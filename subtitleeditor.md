## Subtitle edtior using Mux, Bubble, GPT
1. Use mux to transcribe, see [here](https://www.mux.com/docs/guides/add-autogenerated-captions-and-use-transcripts)
2. Alternatively, we might need to use gladia.ai https://www.gladia.io/product/async-transcription
3. Build a frontend bubble UI into platform to proofread
4. Translate SRT files and transcripts with gtp from proofread SRT version
5. Download burnt version to be used for social with variation
6. Replace existing transcript on mux

### 1. Data Structure

Define/update the following data types in Bubble:

#### `VideoUploads` 
- `mux_asset_id` (text)
- `streaming_url` (text)
- `processed_segments` (list of SubtitleSegment)

#### `Video Tags`  and `Video Tracks`
- `uploaded_srt` (file)
- `status` (option set: `pending`, `ready`, `translated`, `burned`, `replaced`)
- `language_code` (text, e.g., `en`, `fr`)

#### `SubtitleSegment`
- `video` (Video)
- `start_time` (number in seconds or ms)
- `end_time` (number)
- `text` (text, original/proofread)
- `translated_text` (text)
- `speaker_tag` (optional, text)



### 2. Video Playback Integration (Mux) upgrading our existing custom mux plugin (or create a new plugin for this specific step)
Use Mux’s streaming video via an HTML element in Bubble:

```html
<video id="mux-player" controls crossorigin playsinline style="width:100%;">
  <source src="https://stream.mux.com/your_mux_playback_id.m3u8" type="application/x-mpegURL">
</video>
```

Implement JavaScript control with the **Toolbox plugin** or Bubble’s native `Run JavaScript`:
- Seek video to subtitle timing
- Fetch current video time for syncing
- Detect pause/play events


###  3. Subtitle Editor UI (VEED.io-style)
Create a **Repeating Group (RG)** for `SubtitleSegment` items of the selected video:

| Start | End | Text | Actions |
|-------|-----|------|---------|
| Editable input | Editable input | Editable multiline input | Jump to time, Save |

Features:
- Inline editing for `start_time`, `end_time`, and `text`
- "Jump to" button: runs JS to seek video
- Live overlay of subtitles: compare `currentTime` with segment range
- "Add new line" / "Split line" / "Delete" buttons
- Keyboard shortcuts for faster navigation



###  4. Time Sync Engine
#### Real-time preview with overlay (VEED-style)
- Add an `Overlay Text Box` on the video container
- Use `Do every 0.25s` event to:
  - Get `currentTime` from video player via JS
  - Compare with subtitle `start_time` and `end_time`
  - Show matching `text` in overlay
- Use `:filtered:first item` to select the active segment



###  5. Translation with GTP (Already Integrated)
Use our existing GTP integration to:
- Translate each `text` field to `translated_text` after proofreading
- Store translations directly on `SubtitleSegment`
- Offer a toggle in the editor to show **Original vs Translated**
- Optional dropdown: choose output language (`en`, `de`, `fr`, `it`, etc.)

> Trigger translation via API workflow or button click (e.g., "Translate All")



###  6. Burned Version Export

Use backend workflows to:
#### A. Generate SRT file:
- Loop through `SubtitleSegment` list
- Format as `.srt` with start/end in HH:MM:SS,MS format
- Upload file and link to `Video`

#### B. Create Burned-In Video:
- Use FFmpeg or Mux-compatible solution
- Input: original video stream + SRT file
- Output: MP4 with hardcoded subtitles
- Save burned-in result as new asset to mux
  
#### C. Button: "Export for Social"
- Triggers backend workflow
- Downloads final video

### 7. Replace existing SRT file on mux
- Delete original SRT file
- Replace with correct file
- Add translated SRT files as assets
